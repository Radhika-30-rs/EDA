{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ques1-**What is the range of selling prices in the dataset**"
      ],
      "metadata": {
        "id": "0-_RT1v7OtaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "12F6NSvNWkQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"BIKE DETAILS(1).csv\")\n",
        "dfmin_price = df['selling_price'].min()\n",
        "max_price = df['selling_price'].max()\n",
        "price_range = max_price - min_price\n",
        "\n",
        "print(f\"Minimum Selling Price: {min_price}\")\n",
        "print(f\"Maximum Selling Price: {max_price}\")\n",
        "print(f\"Range of Selling Prices: {price_range}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "xAwYWGosOy8k",
        "outputId": "663d79e1-5f48-40d3-ce41-f797b0baed57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'BIKE DETAILS(1).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9fea9ba4b6a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BIKE DETAILS(1).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BIKE DETAILS(1).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 2-**What is the median selling price for bikes in the dataset**"
      ],
      "metadata": {
        "id": "_tlu2UzeXV04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzV14lGzOd3i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file name\n",
        "\n",
        "# Check the column name to ensure it's correct\n",
        "print(df.columns)\n",
        "\n",
        "# Calculate the median selling price\n",
        "median_price = df['selling_price'].median()\n",
        "\n",
        "print(f\"Median Selling Price: {median_price}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 3-**What is the most common seller type**"
      ],
      "metadata": {
        "id": "5KtYYOhtXij-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual filename\n",
        "\n",
        "# Check available columns\n",
        "print(df.columns)\n",
        "\n",
        "# Find the most common (mode) seller type\n",
        "most_common_seller = df['seller_type'].mode()[0]\n",
        "\n",
        "#Count frequency of each seller type\n",
        "seller_counts = df['seller_type'].value_counts()\n",
        "\n",
        "print(f\"Most Common Seller Type: {most_common_seller}\")\n",
        "print(\"\\nSeller Type Distribution:\")\n",
        "print(seller_counts)"
      ],
      "metadata": {
        "id": "tUS8QkXFXrH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 4-**How many bikes have driven more than 50,000 kilometers**"
      ],
      "metadata": {
        "id": "rtcrq03HX30v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your file name\n",
        "\n",
        "# Check the column names\n",
        "print(df.columns)\n",
        "\n",
        "# If the 'km_driven' column is a string with commas (e.g., \"55,000\"), clean it:\n",
        "df['km_driven'] = df['km_driven'].replace(',', '', regex=True).astype(int)\n",
        "\n",
        "# Filter for bikes driven more than 50,000 km\n",
        "high_km_bikes = df[df['km_driven'] > 50000]\n",
        "\n",
        "# Count them\n",
        "count = len(high_km_bikes)\n",
        "print(f\"Number of bikes driven more than 50,000 kilometers: {count}\")\n"
      ],
      "metadata": {
        "id": "5KhFlhC4X_Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 5-**What is the average km_driven value for each ownership type**"
      ],
      "metadata": {
        "id": "ABNj9tqkYRTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file name\n",
        "\n",
        "# Clean the 'km_driven' column if needed (e.g., if it contains commas)\n",
        "df['km_driven'] = df['km_driven'].replace(',', '', regex=True).astype(int)\n",
        "\n",
        "# Group by ownership type and calculate the average km_driven\n",
        "average_km_by_ownership = df.groupby('owner')['km_driven'].mean()\n",
        "\n",
        "# Display the result\n",
        "print(\"Average km_driven for each ownership type:\")\n",
        "print(average_km_by_ownership)\n"
      ],
      "metadata": {
        "id": "fruD8UPvYVXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 6-**What proportion of bikes are from the year 2015 or older**"
      ],
      "metadata": {
        "id": "Jq7NGeabYnW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file name\n",
        "\n",
        "# Check the column names\n",
        "print(df.columns)\n",
        "\n",
        "# Filter bikes from year 2015 or earlier\n",
        "older_bikes = df[df['year'] <= 2015]\n",
        "\n",
        "# Calculate proportion\n",
        "proportion = len(older_bikes) / len(df)\n",
        "\n",
        "# Optionally, format as a percentage\n",
        "percentage = proportion * 100\n",
        "\n",
        "print(f\"Proportion of bikes from 2015 or older: {proportion:.2f}\")\n",
        "print(f\"That's about {percentage:.2f}% of the dataset.\")\n"
      ],
      "metadata": {
        "id": "M8z0tKpvYstk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 7-**What is the trend of missing values across the dataset**"
      ],
      "metadata": {
        "id": "GEelW5BgbsTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file path\n",
        "\n",
        "# Get count of missing values per column\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Filter columns that actually have missing values\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "\n",
        "# Sort by number of missing values (optional)\n",
        "missing_values = missing_values.sort_values(ascending=False)\n",
        "\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "id": "tLUYp3f4bwp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 8-**What is the highest ex_showroom_price recorded, and for which bike**"
      ],
      "metadata": {
        "id": "rDUxkogZckK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file name\n",
        "\n",
        "# Check column names to confirm the correct ones\n",
        "print(df.columns)\n",
        "\n",
        "# Clean the 'ex_showroom_price' column if it has commas or strings\n",
        "df['ex_showroom_price'] = df['ex_showroom_price'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Find the row with the maximum ex_showroom_price\n",
        "max_price_row = df.loc[df['ex_showroom_price'].idxmax()]\n",
        "\n",
        "print(\"Bike with the highest ex-showroom price:\")\n",
        "print(max_price_row)\n"
      ],
      "metadata": {
        "id": "33kgCFMScn93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 9-**B What is the total number of bikes listed by each seller type**"
      ],
      "metadata": {
        "id": "RLKezadCcx0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file name\n",
        "\n",
        "# Check column names\n",
        "print(df.columns)\n",
        "\n",
        "# Count number of bikes per seller type\n",
        "seller_counts = df['seller_type'].value_counts()\n",
        "\n",
        "print(\"Total number of bikes listed by each seller type:\")\n",
        "print(seller_counts)\n"
      ],
      "metadata": {
        "id": "uFkWiSh5c1OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques10-**What is the relationship between selling_price and km_driven for first-owner bikes**"
      ],
      "metadata": {
        "id": "5cf7wdakdTGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your actual file name\n",
        "\n",
        "# Clean km_driven and selling_price if needed\n",
        "df['km_driven'] = df['km_driven'].replace(',', '', regex=True).astype(int)\n",
        "df['selling_price'] = df['selling_price'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Filter for First Owner bikes\n",
        "first_owner_df = df[df['owner'] == 'First Owner']\n",
        "\n",
        "# Scatter plot to visualize relationship\n",
        "sns.scatterplot(x='km_driven', y='selling_price', data=first_owner_df)\n",
        "plt.title('Selling Price vs. KM Driven (First Owner Bikes)')\n",
        "plt.xlabel('Kilometers Driven')\n",
        "plt.ylabel('Selling Price')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cnK92iEKdW4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 11-**Identify and remove outliers in the km_driven column using the IQR method**"
      ],
      "metadata": {
        "id": "ME-mA3Dhddz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your filename\n",
        "\n",
        "# Clean km_driven column if necessary\n",
        "df['km_driven'] = df['km_driven'].replace(',', '', regex=True).astype(int)\n",
        "\n",
        "# Calculate Q1 and Q3\n",
        "Q1 = df['km_driven'].quantile(0.25)\n",
        "Q3 = df['km_driven'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define lower and upper bounds for outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"Lower bound: {lower_bound}\")\n",
        "print(f\"Upper bound: {upper_bound}\")\n",
        "\n",
        "# Filter out the outliers\n",
        "df_no_outliers = df[(df['km_driven'] >= lower_bound) & (df['km_driven'] <= upper_bound)]\n",
        "\n",
        "print(f\"Original dataset size: {len(df)}\")\n",
        "print(f\"Dataset size after removing outliers: {len(df_no_outliers)}\")\n"
      ],
      "metadata": {
        "id": "C8B1KF7pdjrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 12-**Perform a bivariate analysis to visualize the relationship between year and selling_price**"
      ],
      "metadata": {
        "id": "_VEA3d2zdpsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your filename\n",
        "\n",
        "# Clean selling_price if needed\n",
        "df['selling_price'] = df['selling_price'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Scatter plot of year vs selling_price\n",
        "sns.scatterplot(x='year', y='selling_price', data=df, alpha=0.5)\n",
        "plt.title('Selling Price vs Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Selling Price')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qkM0Q6vSduTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 13-**What is the average depreciation in selling price based on the bike's age (current year - manufacturing\n",
        "year)**"
      ],
      "metadata": {
        "id": "X_8bUGyWdzxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your file name\n",
        "\n",
        "# Clean selling_price if needed\n",
        "df['selling_price'] = df['selling_price'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Define the current year (adjust as needed)\n",
        "current_year = 2025\n",
        "\n",
        "# Calculate bike age\n",
        "df['age'] = current_year - df['year']\n",
        "\n",
        "# Remove bikes with age <= 0 (future or same-year bikes)\n",
        "df = df[df['age'] > 0]\n",
        "\n",
        "# Calculate average selling price per age\n",
        "avg_price_by_age = df.groupby('age')['selling_price'].mean().reset_index()\n",
        "\n",
        "# Calculate depreciation: difference in average price between consecutive ages\n",
        "avg_price_by_age['depreciation'] = avg_price_by_age['selling_price'].diff().abs()\n",
        "\n",
        "# Calculate average depreciation per year (mean of all depreciation values)\n",
        "average_depreciation_per_year = avg_price_by_age['depreciation'].mean()\n",
        "\n",
        "print(\"Average depreciation in selling price per year of bike age:\")\n",
        "print(f\"{average_depreciation_per_year:.2f}\")"
      ],
      "metadata": {
        "id": "oWRQaWsWd3RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques14-**Which bike names are priced significantly above the average price for their manufacturing year**"
      ],
      "metadata": {
        "id": "Zq5Vehmud9HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your filename\n",
        "\n",
        "# Clean selling_price column\n",
        "df['selling_price'] = df['selling_price'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Group by year and calculate mean and std dev of selling price\n",
        "year_stats = df.groupby('year')['selling_price'].agg(['mean', 'std']).reset_index()\n",
        "year_stats.rename(columns={'mean': 'year_mean', 'std': 'year_std'}, inplace=True)\n",
        "\n",
        "# Merge stats back into original dataframe\n",
        "df = df.merge(year_stats, on='year', how='left')\n",
        "\n",
        "# Define threshold for \"significantly above average\" (mean + 1 std dev)\n",
        "df['price_above_threshold'] = df['selling_price'] > (df['year_mean'] + df['year_std'])\n",
        "\n",
        "# Filter bikes that meet the condition\n",
        "high_priced_bikes = df[df['price_above_threshold']]\n",
        "\n",
        "# Select relevant columns (assuming 'name' is the bike name)\n",
        "result = high_priced_bikes[['name', 'year', 'selling_price', 'year_mean', 'year_std']]\n",
        "\n",
        "print(\"Bikes priced significantly above average for their manufacturing year:\")\n",
        "print(result.sort_values(by='selling_price', ascending=False))"
      ],
      "metadata": {
        "id": "wArmhXaveDwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques15-**Develop a correlation matrix for numeric columns and visualize it using a heatmap.**"
      ],
      "metadata": {
        "id": "31DQVVKpeJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('bikes.csv')  # Replace with your file name\n",
        "\n",
        "# Convert relevant columns to numeric if needed (example: selling_price, km_driven, ex_showroom_price)\n",
        "df['selling_price'] = df['selling_price'].replace(',', '', regex=True).astype(float)\n",
        "df['km_driven'] = df['km_driven'].replace(',', '', regex=True).astype(float)\n",
        "df['ex_showroom_price'] = df['ex_showroom_price'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Select numeric columns only\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = numeric_df.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ohAbVOGXeS6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA -2"
      ],
      "metadata": {
        "id": "u_VXOF16eo-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 1-**What is the average selling price of cars for each dealer, and how does it compare across different dealers**"
      ],
      "metadata": {
        "id": "jwJZ3xEtet8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your actual file path\n",
        "\n",
        "# Check columns to ensure correct naming\n",
        "print(df.columns)\n",
        "\n",
        "# Group by Dealer_Name and calculate average selling price\n",
        "avg_price_by_dealer = df.groupby('Dealer_Name')['Price ($)'].mean().reset_index()\n",
        "\n",
        "# Sort dealers by average price (descending order)\n",
        "avg_price_by_dealer = avg_price_by_dealer.sort_values(by='Price ($)', ascending=False)\n",
        "\n",
        "print(\"Average selling price of cars by dealer:\")\n",
        "print(avg_price_by_dealer)"
      ],
      "metadata": {
        "id": "Eql2WFFeeyDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques2-** Which car brand (Company) has the highest variation in prices, and what does this tell us about the pricing\n",
        "trends**"
      ],
      "metadata": {
        "id": "rwKF5cAEe0Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file path\n",
        "\n",
        "# Calculate standard deviation of price by company\n",
        "price_std_by_company = df.groupby('Company')['Price ($)'].std().reset_index()\n",
        "\n",
        "# Find the company with the highest price variation\n",
        "max_variation = price_std_by_company.loc[price_std_by_company['Price ($)'].idxmax()]\n",
        "\n",
        "print(f\"Company with highest price variation: {max_variation['Company']}\")\n",
        "print(f\"Standard deviation of price: {max_variation['Price ($)']:.2f}\")\n"
      ],
      "metadata": {
        "id": "zAqXW7Dhe45T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 3-**What is the distribution of car prices for each transmission type, and how do the interquartile ranges\n",
        "compare**"
      ],
      "metadata": {
        "id": "W_fbaB5We-ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your filename\n",
        "\n",
        "# Clean the Price ($) column if necessary\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Boxplot to visualize price distribution by Transmission\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.boxplot(x='Transmission', y='Price ($)', data=df)\n",
        "plt.title('Distribution of Car Prices by Transmission Type')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.xlabel('Transmission Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sBrI6QeefF8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques4-**What is the distribution of car prices across different regions**"
      ],
      "metadata": {
        "id": "HHKyKf_HfKNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file name\n",
        "\n",
        "# Clean Price ($) column if necessary\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Boxplot: price distribution by Dealer_Region\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='Dealer_Region', y='Price ($)', data=df)\n",
        "plt.title('Distribution of Car Prices Across Dealer Regions')\n",
        "plt.xlabel('Dealer Region')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a5chGoGffPUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 5-**What is the distribution of cars based on body styles**"
      ],
      "metadata": {
        "id": "Bo08qh5kfUWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your actual file path\n",
        "\n",
        "# Count number of cars per body style\n",
        "body_style_counts = df['Body Style'].value_counts()\n",
        "\n",
        "print(\"Number of cars by body style:\")\n",
        "print(body_style_counts)\n",
        "\n",
        "# Visualize with a bar plot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=body_style_counts.index, y=body_style_counts.values)\n",
        "plt.title('Distribution of Cars by Body Style')\n",
        "plt.xlabel('Body Style')\n",
        "plt.ylabel('Number of Cars')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ol3XPh0OfYsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 6-**How does the average selling price of cars vary by customer gender and annual income**"
      ],
      "metadata": {
        "id": "6772l1snfd43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your actual file path\n",
        "\n",
        "# Clean Price ($) and Annual Income if needed\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "df['Annual Income'] = df['Annual Income'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Create income bins (you can adjust these ranges as needed)\n",
        "income_bins = [0, 30000, 60000, 90000, 120000, 150000, 1e9]\n",
        "income_labels = ['0-30k', '30k-60k', '60k-90k', '90k-120k', '120k-150k', '150k+']\n",
        "df['Income Group'] = pd.cut(df['Annual Income'], bins=income_bins, labels=income_labels)\n",
        "\n",
        "# Group by Gender and Income Group, calculate average selling price\n",
        "avg_price_gender_income = df.groupby(['Gender', 'Income Group'])['Price ($)'].mean().reset_index()\n",
        "\n",
        "print(avg_price_gender_income)\n",
        "\n",
        "# Visualization: barplot with hue = Gender\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x='Income Group', y='Price ($)', hue='Gender', data=avg_price_gender_income)\n",
        "plt.title('Average Selling Price by Customer Gender and Annual Income Group')\n",
        "plt.xlabel('Annual Income Group (USD)')\n",
        "plt.ylabel('Average Selling Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yjZrDfKzfixU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 7-**What is the distribution of car prices by region, and how does the number of cars sold vary by region**"
      ],
      "metadata": {
        "id": "Y7bdEPJ6fnCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your filename\n",
        "\n",
        "# Clean price column\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# --- 1. Distribution of car prices by Dealer_Region ---\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='Dealer_Region', y='Price ($)', data=df)\n",
        "plt.title('Distribution of Car Prices by Region')\n",
        "plt.xlabel('Dealer Region')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.show()\n",
        "\n",
        "# --- 2. Number of cars sold by Dealer_Region ---\n",
        "region_counts = df['Dealer_Region'].value_counts().reset_index()\n",
        "region_counts.columns = ['Dealer_Region', 'Number of Cars Sold']\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x='Dealer_Region', y='Number of Cars Sold', data=region_counts)\n",
        "plt.title('Number of Cars Sold by Region')\n",
        "plt.xlabel('Dealer Region')\n",
        "plt.ylabel('Number of Cars Sold')\n",
        "plt.show()\n",
        "\n",
        "print(region_counts)"
      ],
      "metadata": {
        "id": "ltKjwQOvfrMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 8-** How does the average car price differ between cars with different engine sizes**"
      ],
      "metadata": {
        "id": "OMN8owbRfw5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file name\n",
        "\n",
        "# Clean Price ($) column if needed\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "# Group by Engine and calculate average price\n",
        "avg_price_by_engine = df.groupby('Engine')['Price ($)'].mean().reset_index()\n",
        "\n",
        "print(\"Average car price by engine size/type:\")\n",
        "print(avg_price_by_engine)\n",
        "\n",
        "# Visualize with a barplot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='Engine', y='Price ($)', data=avg_price_by_engine)\n",
        "plt.title('Average Car Price by Engine Type')\n",
        "plt.xlabel('Engine Type')\n",
        "plt.ylabel('Average Price ($)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RsmcnHZ9f2DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 9-**How do car prices vary based on the customer’s annual income bracket**"
      ],
      "metadata": {
        "id": "dpoMiORXf8WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file path\n",
        "\n",
        "# Clean relevant columns\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "df['Annual Income'] = df['Annual Income'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Define income bins and labels\n",
        "income_bins = [0, 30000, 60000, 90000, 120000, 150000, 1e9]\n",
        "income_labels = ['0-30k', '30k-60k', '60k-90k', '90k-120k', '120k-150k', '150k+']\n",
        "\n",
        "# Create income group column\n",
        "df['Income Bracket'] = pd.cut(df['Annual Income'], bins=income_bins, labels=income_labels)\n",
        "\n",
        "# Calculate average price per income bracket\n",
        "avg_price_by_income = df.groupby('Income Bracket')['Price ($)'].mean().reset_index()\n",
        "\n",
        "print(avg_price_by_income)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='Income Bracket', y='Price ($)', data=avg_price_by_income)\n",
        "plt.title('Average Car Price by Customer Annual Income Bracket')\n",
        "plt.xlabel('Annual Income Bracket (USD)')\n",
        "plt.ylabel('Average Car Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XG4nCh6ngAjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 10-**What are the top 5 car models with the highest number of sales, and how does their price distribution look**"
      ],
      "metadata": {
        "id": "Mvd8FuAtgF2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file path\n",
        "\n",
        "# Clean Price column if needed\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Count sales per model and get top 5\n",
        "top5_models = df['Model'].value_counts().head(5).index.tolist()\n",
        "print(\"Top 5 car models by number of sales:\")\n",
        "print(df['Model'].value_counts().head(5))\n",
        "\n",
        "# Filter dataset for only top 5 models\n",
        "top5_df = df[df['Model'].isin(top5_models)]\n",
        "\n",
        "# Plot price distribution for top 5 models\n",
        "plt.figure(figsize=(12,7))\n",
        "sns.boxplot(x='Model', y='Price ($)', data=top5_df)\n",
        "plt.title('Price Distribution of Top 5 Car Models by Sales')\n",
        "plt.xlabel('Car Model')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CWSJcZJPgKME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 11-**How does car price vary with engine size across different car colors, and which colors have the highest price\n",
        "variation**"
      ],
      "metadata": {
        "id": "HZdY3dkhgO5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your path\n",
        "\n",
        "# Clean Price column\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# 1. Average price by Engine and Color\n",
        "avg_price_engine_color = df.groupby(['Engine', 'Color'])['Price ($)'].mean().reset_index()\n",
        "\n",
        "# Pivot for better visualization (optional)\n",
        "pivot_table = avg_price_engine_color.pivot(index='Engine', columns='Color', values='Price ($)')\n",
        "\n",
        "print(\"Average Price by Engine and Color:\")\n",
        "print(pivot_table)\n",
        "\n",
        "# 2. Calculate price variation (std dev) by Color\n",
        "price_std_by_color = df.groupby('Color')['Price ($)'].std().reset_index().sort_values(by='Price ($)', ascending=False)\n",
        "\n",
        "print(\"\\nPrice variation (std dev) by Color:\")\n",
        "print(price_std_by_color)\n",
        "\n",
        "# 3. Visualization of average prices by engine and color (using a heatmap)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".0f\", cmap='YlGnBu', cbar_kws={'label': 'Avg Price ($)'})\n",
        "plt.title('Average Car Price by Engine Size and Color')\n",
        "plt.ylabel('Engine Size')\n",
        "plt.xlabel('Car Color')\n",
        "plt.show()\n",
        "\n",
        "# 4. Barplot for price variation by color\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x='Color', y='Price ($)', data=price_std_by_color)\n",
        "plt.title('Price Variation (Standard Deviation) by Car Color')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Price Std Dev ($)')\n",
        "plt.xlabel('Car Color')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s2LHRmhugTdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 12-**Is there any seasonal trend in car sales based on the date of sale**"
      ],
      "metadata": {
        "id": "wftpHa8IgVur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file path\n",
        "\n",
        "# Convert 'Date' column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract month and year\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Month_Name'] = df['Date'].dt.strftime('%b')  # Jan, Feb, etc.\n",
        "\n",
        "# Group sales count by month (across all years)\n",
        "monthly_sales = df.groupby('Month')['Car_id'].count().reset_index()\n",
        "\n",
        "# Order months correctly for plotting\n",
        "monthly_sales['Month_Name'] = monthly_sales['Month'].apply(lambda x: pd.to_datetime(str(x), format='%m').strftime('%b'))\n",
        "monthly_sales = monthly_sales.sort_values('Month')\n",
        "\n",
        "# Plot sales by month\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.lineplot(data=monthly_sales, x='Month_Name', y='Car_id', marker='o')\n",
        "plt.title('Monthly Car Sales Volume (All Years Combined)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Cars Sold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ciBS3IOOgdLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques13-**How does the car price distribution change when considering different combinations of body style and\n",
        "transmission type**"
      ],
      "metadata": {
        "id": "mFBRDTqrgjV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file path\n",
        "\n",
        "# Clean Price column if necessary\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Create a combined category for easier plotting (optional)\n",
        "df['Body_Transmission'] = df['Body Style'] + ' / ' + df['Transmission']\n",
        "\n",
        "# Plot price distribution by Body Style and Transmission type\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.boxplot(x='Body Style', y='Price ($)', hue='Transmission', data=df)\n",
        "plt.title('Car Price Distribution by Body Style and Transmission Type')\n",
        "plt.xlabel('Body Style')\n",
        "plt.ylabel('Price ($)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Transmission')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9515B2kygmnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques14-**What is the correlation between car price, engine size, and annual income of customers, and how do these\n",
        "features interact**"
      ],
      "metadata": {
        "id": "-4vKbybigq1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your path\n",
        "\n",
        "# Clean and convert relevant columns\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "df['Annual Income'] = df['Annual Income'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# For engine size, if it's numeric (e.g., \"1500cc\"), extract numeric part; else, you may need mapping\n",
        "# Here assuming engine size is a numeric value or you can extract numbers from string like \"1500cc\"\n",
        "import re\n",
        "\n",
        "def extract_engine_size(engine_str):\n",
        "    if pd.isnull(engine_str):\n",
        "        return None\n",
        "    nums = re.findall(r'\\d+', engine_str)\n",
        "    return float(nums[0]) if nums else None\n",
        "\n",
        "df['Engine_Size'] = df['Engine'].apply(extract_engine_size)\n",
        "\n",
        "# Drop rows with missing values in these columns\n",
        "df_clean = df.dropna(subset=['Price ($)', 'Annual Income', 'Engine_Size'])\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = df_clean[['Price ($)', 'Annual Income', 'Engine_Size']].corr()\n",
        "print(\"Correlation matrix:\\n\", corr_matrix)\n",
        "\n",
        "# Visualize correlation heatmap\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Pairplot to visualize interactions\n",
        "sns.pairplot(df_clean[['Price ($)', 'Annual Income', 'Engine_Size']])\n",
        "plt.suptitle('Pairplot of Price, Annual Income, and Engine Size', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6IDGV42Wguf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques15-** How does the average car price vary across different car models and engine types?**"
      ],
      "metadata": {
        "id": "3yTu95qIg1hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cars.csv')  # Replace with your file path\n",
        "\n",
        "# Clean price column\n",
        "df['Price ($)'] = df['Price ($)'].replace(',', '', regex=True).astype(float)\n",
        "\n",
        "# Group by Model and Engine, calculate average price\n",
        "avg_price = df.groupby(['Model', 'Engine'])['Price ($)'].mean().reset_index()\n",
        "\n",
        "# Pivot for heatmap format\n",
        "pivot_table = avg_price.pivot(index='Model', columns='Engine', values='Price ($)')\n",
        "\n",
        "print(pivot_table)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(14,10))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".0f\", cmap='coolwarm', cbar_kws={'label': 'Avg Price ($)'})\n",
        "plt.title('Average Car Price by Model and Engine Type')\n",
        "plt.xlabel('Engine Type')\n",
        "plt.ylabel('Car Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8DW077bvg6cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA 3"
      ],
      "metadata": {
        "id": "p3QfTmBchYok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques1-**What is the average rating for each product category**"
      ],
      "metadata": {
        "id": "OSiIXVzshbza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Calculate average rating by category\n",
        "avg_rating_by_category = df.groupby('category')['rating'].mean().reset_index()\n",
        "\n",
        "# Sort by average rating descending (optional)\n",
        "avg_rating_by_category = avg_rating_by_category.sort_values(by='rating', ascending=False)\n",
        "\n",
        "print(avg_rating_by_category)\n"
      ],
      "metadata": {
        "id": "luXgma35hsHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 2-** What are the top rating_count products by category**"
      ],
      "metadata": {
        "id": "utItNYhThwum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# For each category, find the product(s) with the highest rating_count\n",
        "top_rating_count_products = df.loc[df.groupby('category')['rating_count'].idxmax()]\n",
        "\n",
        "# Select relevant columns to display\n",
        "top_rating_count_products = top_rating_count_products[['category', 'product_name', 'rating_count', 'rating']]\n",
        "\n",
        "print(top_rating_count_products)\n"
      ],
      "metadata": {
        "id": "sbrBI0b3hz43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques3-**What is the distribution of discounted prices vs. actual prices?\n"
      ],
      "metadata": {
        "id": "5DsZEcAAh6jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Convert price columns to numeric, handle errors\n",
        "df['discounted_price'] = pd.to_numeric(df['discounted_price'], errors='coerce')\n",
        "df['actual_price'] = pd.to_numeric(df['actual_price'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing prices\n",
        "df_clean = df.dropna(subset=['discounted_price', 'actual_price'])\n",
        "\n",
        "# Plot distributions using KDE\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.kdeplot(df_clean['actual_price'], label='Actual Price', shade=True)\n",
        "sns.kdeplot(df_clean['discounted_price'], label='Discounted Price', shade=True)\n",
        "plt.title('Distribution of Actual Prices vs. Discounted Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yc4NyJIEivr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques4-**How does the average discount percentage vary across categories**"
      ],
      "metadata": {
        "id": "BUVOkf_giEGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Convert discount_percentage to numeric if needed\n",
        "df['discount_percentage'] = pd.to_numeric(df['discount_percentage'], errors='coerce')\n",
        "\n",
        "# Calculate average discount percentage by category\n",
        "avg_discount_by_category = df.groupby('category')['discount_percentage'].mean().reset_index()\n",
        "\n",
        "# Sort by average discount descending for better visualization\n",
        "avg_discount_by_category = avg_discount_by_category.sort_values(by='discount_percentage', ascending=False)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(data=avg_discount_by_category, x='discount_percentage', y='category', palette='coolwarm')\n",
        "plt.title('Average Discount Percentage by Product Category')\n",
        "plt.xlabel('Average Discount Percentage (%)')\n",
        "plt.ylabel('Product Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fGMrElGoi6Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 5-**What are the most popular product names**"
      ],
      "metadata": {
        "id": "YL3v4iUsi7YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Group by product name and sum the rating counts\n",
        "popularity = df.groupby('product_name')['rating_count'].sum().reset_index()\n",
        "\n",
        "# Sort by rating_count descending\n",
        "top_popular_products = popularity.sort_values(by='rating_count', ascending=False)\n",
        "\n",
        "# Show top 10 popular products\n",
        "print(top_popular_products.head(10))"
      ],
      "metadata": {
        "id": "Ot3NpmYSjAIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 6-** What are the most popular product keywords**"
      ],
      "metadata": {
        "id": "N_MS5eROjEsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Combine all product names into one large text\n",
        "all_product_names = ' '.join(df['product_name'].dropna().str.lower())\n",
        "\n",
        "# Simple tokenization: split by non-alphabetic characters\n",
        "words = re.findall(r'\\b[a-z]{2,}\\b', all_product_names)  # words with 2+ letters\n",
        "\n",
        "# Count frequency\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Most common keywords\n",
        "common_keywords = word_counts.most_common(20)\n",
        "print(common_keywords)"
      ],
      "metadata": {
        "id": "vSrOKgEOjJMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 7-**What are the most popular product reviews**"
      ],
      "metadata": {
        "id": "Pu9g_-OmjSOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Calculate length of each review content\n",
        "df['review_length'] = df['review_content'].fillna('').apply(len)\n",
        "\n",
        "# Option 1: Top 10 longest reviews\n",
        "top_longest_reviews = df.sort_values(by='review_length', ascending=False).head(10)\n",
        "\n",
        "# Option 2: Top reviews for products with highest rating counts\n",
        "# Get products with highest rating_count\n",
        "top_products = df.groupby('product_id')['rating_count'].max().sort_values(ascending=False).head(10).index\n",
        "\n",
        "top_reviews_for_popular_products = df[df['product_id'].isin(top_products)].sort_values(by='review_length', ascending=False).head(10)\n",
        "\n",
        "print(\"Top 10 Longest Reviews:\")\n",
        "print(top_longest_reviews[['product_name', 'review_title', 'review_length', 'rating', 'review_content']])\n",
        "\n",
        "print(\"\\nTop 10 Reviews for Popular Products:\")\n",
        "print(top_reviews_for_popular_products[['product_name', 'review_title', 'rating', 'review_content']])"
      ],
      "metadata": {
        "id": "JDt7QxnCjWpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 8-**What is the correlation between discounted_price and rating**"
      ],
      "metadata": {
        "id": "Q5GkQQXejfWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Convert columns to numeric if needed\n",
        "df['discounted_price'] = pd.to_numeric(df['discounted_price'], errors='coerce')\n",
        "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values in these columns\n",
        "df_clean = df.dropna(subset=['discounted_price', 'rating'])\n",
        "\n",
        "# Calculate Pearson correlation\n",
        "correlation = df_clean['discounted_price'].corr(df_clean['rating'])\n",
        "print(f\"Correlation between discounted price and rating: {correlation:.3f}\")"
      ],
      "metadata": {
        "id": "AuoLlTEIjjlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques9-*** What are the Top 5 categories based on the highest ratings**"
      ],
      "metadata": {
        "id": "ssC577UdjpYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('amazon_sales.csv')  # Replace with your file path\n",
        "\n",
        "# Convert rating to numeric if needed\n",
        "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
        "\n",
        "# Calculate average rating per category\n",
        "avg_rating_by_category = df.groupby('category')['rating'].mean().reset_index()\n",
        "\n",
        "# Sort descending and get top 5\n",
        "top_5_categories = avg_rating_by_category.sort_values(by='rating', ascending=False).head(5)\n",
        "\n",
        "print(top_5_categories)"
      ],
      "metadata": {
        "id": "bTo3efmLjvl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 10-**\u001d' Identify any potential areas for improvement or optimization based on the data analysis**"
      ],
      "metadata": {
        "id": "EaP24g1fj1Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Pricing & Discounts\n",
        "Optimize Discount Strategies: Some categories may have high average discounts but not a corresponding increase in sales or ratings. Adjust discounts selectively to improve profitability without hurting demand.\n",
        "\n",
        "Price Sensitivity: Products with low ratings but high prices might benefit from better pricing or bundling offers."
      ],
      "metadata": {
        "id": "3Lob63Ooj42b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA 4"
      ],
      "metadata": {
        "id": "8d8cwxTPke06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques1-**.\u0016 Read the dataframe, check null value if present then do the needful, check duplicate row , if present then do\n",
        "the needful\u0016**"
      ],
      "metadata": {
        "id": "vEHeLcRwkgAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Replace with your actual file path\n",
        "\n",
        "# Step 2: Check for null values\n",
        "print(\"Null values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle null values if present\n",
        "# Option A: Drop rows with any null values\n",
        "df_clean = df.dropna()\n",
        "\n",
        "# Option B (alternative): Fill nulls with appropriate values (example: fill numeric nulls with median)\n",
        "# df['Popularity'].fillna(df['Popularity'].median(), inplace=True)\n",
        "# df['Duration (ms)'].fillna(df['Duration (ms)'].median(), inplace=True)\n",
        "# (Fill other columns as needed)\n",
        "\n",
        "# Step 3: Check for duplicate rows\n",
        "duplicates = df_clean.duplicated()\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
        "\n",
        "# Remove duplicate rows if any\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "\n",
        "# Final dataframe info\n",
        "print(\"\\nDataframe after cleaning:\")\n",
        "print(df_clean.info())\n",
        "\n",
        "# Optional: Save cleaned dataframe\n",
        "# df_clean.to_csv('spotify_hiphop_data_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "52sTXPDtkkDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques2-**\u0016 What is the distribution of popularity among the tracks in the dataset? Visualize it using a histogram\u0016**"
      ],
      "metadata": {
        "id": "cgPMYnK-klyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset (assuming you already cleaned it)\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Or your cleaned file path\n",
        "\n",
        "# Plot histogram of the 'Popularity' column\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df['Popularity'], bins=30, kde=True, color='purple')\n",
        "plt.title('Distribution of Track Popularity')\n",
        "plt.xlabel('Popularity Score')\n",
        "plt.ylabel('Number of Tracks')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FwcGTBmbkptW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques3-**s there any relationship between the popularity and the duration of tracks? Explore this using a scatter plot\u0016**"
      ],
      "metadata": {
        "id": "Q3p4g-hWkvNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset (use cleaned dataframe if available)\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Replace with cleaned file if you have one\n",
        "\n",
        "# Convert duration from milliseconds to minutes for better interpretability\n",
        "df['Duration_min'] = df['Duration (ms)'] / 60000\n",
        "\n",
        "# Scatter plot with regression line\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x='Duration_min', y='Popularity', data=df, alpha=0.6)\n",
        "sns.regplot(x='Duration_min', y='Popularity', data=df, scatter=False, color='red')\n",
        "plt.title('Relationship between Track Duration and Popularity')\n",
        "plt.xlabel('Duration (minutes)')\n",
        "plt.ylabel('Popularity Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5DXSWAoek0Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 4-**Which artist has the highest number of tracks in the dataset? Display the count of tracks for each artist using\n",
        "a countplot**"
      ],
      "metadata": {
        "id": "AN76ItGfk4Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Count number of tracks per artist\n",
        "track_counts = df['Artist'].value_counts()\n",
        "print(\"Artist with the highest number of tracks:\")\n",
        "print(track_counts.head(1))  # Display top artist\n",
        "\n",
        "# Plot countplot for top 10 artists for clarity\n",
        "top_artists = track_counts.head(10).index\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(y='Artist', data=df[df['Artist'].isin(top_artists)], order=top_artists, palette='viridis')\n",
        "plt.title('Top 10 Artists by Number of Tracks')\n",
        "plt.xlabel('Number of Tracks')\n",
        "plt.ylabel('Artist')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TlfXxpFkk74h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 5-**What are the top 5 least popular tracks in the dataset? Provide the artist name and track name for each**"
      ],
      "metadata": {
        "id": "CGQPnr7RlA3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Sort by popularity ascending and get top 5 least popular tracks\n",
        "least_popular_tracks = df.sort_values(by='Popularity').head(5)\n",
        "\n",
        "# Select relevant columns\n",
        "result = least_popular_tracks[['Artist', 'Track Name', 'Popularity']]\n",
        "\n",
        "print(\"Top 5 Least Popular Tracks:\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YSR7hgMYlE0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques 6-**\u0016 Among the top 5 most popular artists, which artist has the highest popularity on average? Calculate and\n",
        "display the average popularity for each artist**"
      ],
      "metadata": {
        "id": "Z8lmUlValKTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Step 1: Find top 5 artists by number of tracks\n",
        "top_artists = df['Artist'].value_counts().head(5).index\n",
        "\n",
        "# Step 2: Calculate average popularity for these top artists\n",
        "avg_popularity = df[df['Artist'].isin(top_artists)].groupby('Artist')['Popularity'].mean().reset_index()\n",
        "\n",
        "# Step 3: Sort descending by average popularity\n",
        "avg_popularity = avg_popularity.sort_values(by='Popularity', ascending=False)\n",
        "\n",
        "print(\"Average Popularity of Top 5 Most Popular Artists:\")\n",
        "print(avg_popularity)\n",
        "\n",
        "# Optional: Identify artist with highest average popularity\n",
        "top_artist = avg_popularity.iloc[0]\n",
        "print(f\"\\nArtist with highest average popularity among top 5: {top_artist['Artist']} ({top_artist['Popularity']:.2f})\")"
      ],
      "metadata": {
        "id": "73RpwQgclOk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques7-**For the top 5 most popular artists, what are their most popular tracks? List the track name for each artist**"
      ],
      "metadata": {
        "id": "_XwRQ5OnlTOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Get top 5 artists by number of tracks\n",
        "top_artists = df['Artist'].value_counts().head(5).index\n",
        "\n",
        "# Filter dataset for top artists\n",
        "top_artist_tracks = df[df['Artist'].isin(top_artists)]\n",
        "\n",
        "# Find most popular track for each artist\n",
        "most_popular_tracks = top_artist_tracks.loc[top_artist_tracks.groupby('Artist')['Popularity'].idxmax()]\n",
        "\n",
        "# Select relevant columns\n",
        "result = most_popular_tracks[['Artist', 'Track Name', 'Popularity']]\n",
        "\n",
        "print(\"Most Popular Track for Each of the Top 5 Artists:\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Zv91p0-glYOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques8-** Visualize relationships between multiple numerical variables simultaneously using a pair plot**"
      ],
      "metadata": {
        "id": "6Q9jCBtalnyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Convert Duration to minutes for better readability\n",
        "df['Duration_min'] = df['Duration (ms)'] / 60000\n",
        "\n",
        "# Select numeric columns for pairplot\n",
        "numeric_cols = ['Popularity', 'Duration_min']\n",
        "\n",
        "# Create pairplot\n",
        "sns.pairplot(df[numeric_cols], diag_kind='kde', plot_kws={'alpha':0.6, 's':40, 'edgecolor':'k'})\n",
        "\n",
        "plt.suptitle('Pair Plot of Numerical Variables', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cg2P2zoPlrp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques9-**Does the duration of tracks vary significantly across different artists? Explore this visually using a box plot or\n",
        "violin plot**"
      ],
      "metadata": {
        "id": "SOHghcJxlxlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Convert duration to minutes\n",
        "df['Duration_min'] = df['Duration (ms)'] / 60000\n",
        "\n",
        "# For clarity, limit to top 10 artists by number of tracks\n",
        "top_artists = df['Artist'].value_counts().head(10).index\n",
        "df_top = df[df['Artist'].isin(top_artists)]\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.boxplot(x='Artist', y='Duration_min', data=df_top, palette='Set3')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Track Duration Distribution Across Top 10 Artists')\n",
        "plt.xlabel('Artist')\n",
        "plt.ylabel('Duration (minutes)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ytVFYE8ol2Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ques10-**How does the distribution of track popularity vary for different artists? Visualize this using a swarm plot or a\n",
        "violin plot.**"
      ],
      "metadata": {
        "id": "ciniu2iTl7Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('spotify_hiphop_data.csv')  # Use cleaned data if available\n",
        "\n",
        "# Limit to top 10 artists by number of tracks\n",
        "top_artists = df['Artist'].value_counts().head(10).index\n",
        "df_top = df[df['Artist'].isin(top_artists)]\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.violinplot(x='Artist', y='Popularity', data=df_top, palette='coolwarm')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Distribution of Track Popularity Across Top 10 Artists')\n",
        "plt.xlabel('Artist')\n",
        "plt.ylabel('Popularity Score')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2RNchzTmAZs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}